# QuickChat

A sleek, feature-rich chat interface for local LLM inference with Ollama on GNOME Linux or Windows with chat Forking feature.  

Welcome to **QuickChat**! ğŸ‰ This desktop app brings a professional, intuitive experience to your local AI chats. Built with PySide6 for speed and style, it's designed to make interacting with Ollama models feel effortless and fun. Whether you're brainstorming ideas or analyzing images, QuickChat has you coveredâ€”all locally on your machine.  

<img src="icon.png" alt="QuickChat Icon" width="200" height="200">
<img src="gui.png" alt="GUI Example">

## Table of Contents
- [Features](#-features)
- [Quick Start](#-quick-start)
- [System Requirements](#-system-requirements)
- [Installation](#-installation)
- [Usage Guide](#-usage-guide)
- [Architecture](#-architecture)
- [Advanced Features](#-advanced-features)
- [Troubleshooting](#-troubleshooting)
- [Performance Tips](#-performance-tips)
- [Privacy & Security](#-privacy--security)
- [Uninstallation](#-uninstallation)
- [Contributing](#-contributing)
- [Acknowledgments](#-acknowledgments)
- [Changelog](#-changelog)

## âœ¨ Features

QuickChat packs powerful tools into a clean interface. Here's what you'll love:

### ğŸ§  Advanced Thinking
- **Dual Modes**: Supports parameter-based (Ollama API) and directive-based (GGUF with `/think`/`/no_think`).
- **Auto-Detection**: Checks model capabilities on load.
- **Visualization**: Real-time thinking bubbles (collapsible).
- **Control**: Toggle per message, with safeguards.

### ğŸ‘ï¸ Vision & Images
- **Formats**: PNG, JPG, WebP, and more.
- **Auto-Enable**: For vision-capable models.
- **Smart Handling**: Sends only the latest image; preserves thumbnails in history.

### ğŸ’¬ Conversation Tools
- **Smart Naming**: AI-generated titles (no thinking delay).
- **Forking**: Branch from any message via right-click.
- **History**: SQLite-backed persistence.
- **Export/Import**: Markdown (readable) or JSON (full data).
- **Search**: Quick keyword filtering in sidebar.

### ğŸ¨ UI/UX
- **Themes**: Dark/Light with auto-save.
- **Animations**: Smooth notifications and transitions.
- **Streaming**: Real-time response generation.
- **Shortcuts**: Enter to send, Ctrl+Enter or Shift+Enter for newline.
- **Responsive**: Adapts to any window size.

### ğŸ›¡ï¸ Safeguards
- **During Generation**: Locks chat switches, imports, model changes; allows typing and stopping.
- **Notifications**: Friendly alerts explain restrictions.

### âš™ï¸ Configuration
- **Model Selector**: Dropdown with refresh; set default.
- **Settings**: Theme, default model, app info.

## ğŸš€ Quick Start

Let's get you chatting in minutes!

### Installation
Run the script for a hassle-free setup:
```bash
# Clone or download, then:
cd QuickChat
bash ./install.sh
```
It handles venv, dependencies, and desktop shortcuts.

### Launch
- Terminal: `quickchat`
- Or search "QuickChat" in your menu.

### First Steps
1. Start Ollama (`ollama serve`).
2. Pick a model from the dropdown.
3. Type and hit Enterâ€”watch the magic!
4. Try extras: Toggle ğŸ§  for thinking or ğŸ–¼ï¸ for images.

## ğŸ“‹ System Requirements

- **OS**: GNOME Linux (Ubuntu 20.04+, etc.) or Windows.
- **Python**: 3.8+.
- **RAM**: 4GB min (8GB+ recommended).
- **Ollama**: Local install with models.

Dependencies (auto-installed): PySide6, ollama, SQLAlchemy, qasync, mistune, pygments, aiohttp, Pillow, matplotlib.

## ğŸ“¦ Installation

### Automated (Recommended)
`bash ./install.sh` â€“ Sets up everything.

### Manual (Linux)
```bash
mkdir -p ~/.local/share/quickchat/app
cd ~/.local/share/quickchat/app
# Copy files: src/, main.py, config/, icon.png, requirements.txt
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
# Create launcher in ~/.local/bin/quickchat
```

### Development
```bash
git clone <repo>
cd QuickChat
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python3 main.py
```

### Windows
Double-click `setup.bat` (installs venv/deps), then `run.bat` to launch. 

Manual:
```cmd
python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
python main.py
```

## ğŸ® Usage Guide

### Basic Chatting
Select model, type message, Enter to send. Responses stream live!

### Thinking Mode
Toggle ğŸ§ â€”see reasoning in bubbles. Auto-adapts to model type.

### Vision Mode
Toggle ğŸ–¼ï¸, attach image, ask questions. Thumbnails stay in history.

### Managing Chats
- **New/Switch**: Buttons in sidebar (locked during generation).
- **Fork**: Right-click message > "Fork Chat from Here".
- **Search**: Top sidebar box.
- **Export**: Right-click chat > Markdown/JSON.
- **Import**: Button in sidebar.

### Customization
Settings dialog: Theme toggle, default model. Changes persist.

## ğŸ—ï¸ Architecture

Compact and modular:
- **core/**: Database (SQLite/SQLAlchemy).
- **services/**: Chat management, Ollama client, settings, Markdown.
- **ui/**: Main window, widgets (header/sidebar/chat/input), dialogs.
- Entry: `main.py`.

## ğŸ”§ Advanced Features

- **Capability Detection**: API first, then keywords (e.g., qwen3).
- **Message Prep**: Adds directives or params based on model.
- **Thinking Extraction**: Strips `<think>` tags during streaming.
- **Vision Opts**: Sends latest image only; caches metadata.
- **State Management**: Protects UI during responses/thinking/titling.

## ğŸ› Troubleshooting

- **Won't Start**: Reinstall; check Python/Ollama.
- **Thinking Disabled**: Use supported models; refresh list.
- **Images Fail**: Check format/model; verify file.
- **No Scrollbar**: Use wheel/arrows in dropdown.
- **Chats Gone**: Restore from `~/.local/share/quickchat/data/quickchat.db`.

## ğŸ“Š Performance Tips

- Use small/quantized models.
- Close apps; use SSD for Ollama.
- Smaller images speed up vision.
- Archive old chats for faster loading.

## ğŸ”’ Privacy & Security

Everything localâ€”no clouds, tracking, or telemetry. Data in `~/.local/share/quickchat/` and `~/.config/QuickChat/`.

## ğŸ—‘ï¸ Uninstallation

`bash ./uninstall.sh` â€“ Option to keep data. Or manual remove.

## ğŸ¤ Contributing

Join in! Help with UI, perf, features, docs, or bugs. Submit PRs with details.

## ğŸ™ Acknowledgments

Thanks to Ollama, PySide6, Mistune, SQLAlchemy, and the local AI community!

## ğŸ“ Changelog

### v1.0.0
Initial release: Thinking/vision support, full chat tools, themes, safeguards.

---

Made with â¤ï¸ for local AI enthusiasts. Happy chattingâ€”let's build something amazing! ğŸš€
